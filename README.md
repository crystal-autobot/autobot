<p align="center">
  <img src="assets/logo.png" alt="Autobot logo" width="800">
</p>

# Autobot

**Ultra-efficient personal AI assistant powered by Crystal**

Compiled binary â€¢ Multi-provider LLM â€¢ Chat integrations â€¢ Plugin system

## Why Autobot?

**Production-grade AI automation** built with [Crystal](https://crystal-lang.org) â€” engineered for token efficiency, security, and reliability.

| What | How |
|------|-----|
| **ðŸŽ¯ Token Efficient** | Structured tool results â€¢ Memory consolidation â€¢ Minimal context overhead â€¢ Session management |
| **ðŸ“Š Observable** | Status-based logging â€¢ Credential sanitization â€¢ Token tracking â€¢ Operation audit trails |
| **ðŸ”’ Secure** | Docker/bubblewrap isolation â€¢ OS-level workspace restrictions â€¢ No manual path validation â€¢ SSRF protection â€¢ Command guards |
| **âš¡ Lightweight** | 2MB binary â€¢ <50MB Docker â€¢ Zero runtime deps â€¢ <100ms startup â€¢ Streaming I/O |

### ðŸ›¡ï¸ Production-Grade Security

Autobot uses **kernel-enforced sandboxing** via Docker or bubblewrap â€” not application-level validation. When the LLM executes commands:

- âœ… **Only workspace directory is accessible** (enforced by Linux mount namespaces)
- âœ… **Everything else is invisible** to the LLM â€” your `/home`, `/etc`, system files simply don't exist in the sandbox
- âœ… **No symlink exploits, TOCTOU, or path traversal** â€” kernel guarantees workspace isolation
- âœ… **Process isolation** â€” LLM can't see or interact with host processes
- âœ… **Auto-detected** â€” Uses Docker (macOS/production) or bubblewrap (Linux/dev)

**Example:** When LLM tries `ls ../`, it fails at the OS level because parent directories aren't mounted. No regex patterns, no validation bypasses â€” just kernel namespaces.

**â†’ [Security Architecture](docs/security.md)**

## âœ¨ Features

**Core Engine**
- Multi-provider LLM (Anthropic, OpenAI, DeepSeek, Groq, Gemini, OpenRouter, vLLM)
- JSONL sessions with memory consolidation
- Built-in tools: file ops, shell exec, web search/fetch

**Integrations**
- Chat channels: Telegram, Slack, WhatsApp
- Cron scheduler with expressions and intervals
- Plugin system for custom tools
- Bash script auto-discovery as tools

**Advanced**
- Skills: Markdown-based with frontmatter
- Custom commands: macros or bash scripts
- Subagents for parallel tasks
- Full observability: tokens, files, operations

## ðŸš€ Quick Start

### 1. Install

```bash
# From source
git clone https://github.com/crystal-autobot/autobot.git
cd autobot
sudo make install

# Or with Docker (multi-arch: amd64, arm64)
docker pull ghcr.io/crystal-autobot/autobot:latest
```

### 2. Initialize

```bash
autobot onboard
```

Creates `~/.config/autobot/` with config, workspace, sessions, skills, and logs.

### 3. Configure

Edit `~/.config/autobot/config.yml`:

```yaml
providers:
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"

channels:
  telegram:
    enabled: true
    token: "YOUR_BOT_TOKEN"
    allow_from: ["your_username"]
```

### 4. Run

```bash
# Interactive mode
autobot agent

# Gateway (all channels)
autobot gateway
# âœ“ Plugins: 5 loaded
# âœ“ Tools: 12 registered
# âœ“ Sandbox: docker (container isolation)
# âœ“ Gateway ready

# Single command
autobot agent -m "Summarize this project"
```

Autobot automatically detects and logs the sandbox method on startup â€” Docker on macOS/production, bubblewrap on Linux.

**â†’ [Full Quick Start Guide](docs/quickstart.md)**

## ðŸ“š Documentation

| Document | Description |
|----------|-------------|
| [Quick Start](docs/quickstart.md) | Installation and first steps |
| [Configuration](docs/configuration.md) | Complete config reference |
| [Security](docs/security.md) | Security model and best practices |
| [Deployment](docs/deployment.md) | Production deployment with proper user/permissions |
| [CLI Reference](docs/cli.md) | All commands and options |
| [Architecture](docs/architecture.md) | System design and components |
| [Plugins](docs/plugins.md) | Building and using plugins |
| [Examples](docs/examples.md) | Use cases and code samples |
| [Development](docs/development.md) | Contributing and local setup |

## ðŸ’¡ Examples

<details>
<summary><b>Telegram Bot with Custom Commands</b></summary>

```yaml
channels:
  telegram:
    enabled: true
    token: "BOT_TOKEN"
    allow_from: ["your_username"]
    custom_commands:
      macros:
        summarize: "Summarize our conversation in 3 bullet points"
        translate: "Translate the following to English"
      scripts:
        deploy: "/home/user/scripts/deploy.sh"
        status: "/home/user/scripts/system_status.sh"
```

Use `/summarize` or `/deploy` in Telegram to trigger them.

</details>

<details>
<summary><b>Cron Scheduler</b></summary>

```bash
# Daily morning greeting
autobot cron add --name "morning" \
  --message "Good morning! Here's today's summary" \
  --cron "0 9 * * *"

# Hourly reminder
autobot cron add --name "reminder" \
  --message "Stand up and stretch!" \
  --every 3600

# One-time meeting notification
autobot cron add --name "meeting" \
  --message "Team sync in 5 minutes!" \
  --at "2025-03-01T10:00:00"
```

</details>

<details>
<summary><b>Multi-Provider Setup</b></summary>

```yaml
providers:
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
  openai:
    api_key: "${OPENAI_API_KEY}"
  deepseek:
    api_key: "${DEEPSEEK_API_KEY}"
  vllm:
    api_base: "http://localhost:8000"
    api_key: "token"

agents:
  defaults:
    model: "anthropic/claude-sonnet-4-5"
    max_tokens: 8192
    temperature: 0.7
```

</details>

**â†’ [More Examples](docs/examples.md)**

## ðŸ”§ Development

### Prerequisites
- [Crystal](https://crystal-lang.org/install/) >= 1.10.0

### Commands

```bash
make build          # Debug binary
make release        # Optimized binary (~2MB)
make test           # Run test suite
make lint           # Run ameba linter
make format         # Format code

make docker         # Build Docker image
make release-all    # Cross-compile for all platforms
make help           # Show all targets
```

**â†’ [Development Guide](docs/development.md)**
